{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=4\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import utils.plot_functions as pf\n",
    "import numpy as np\n",
    "from cae_model import cae\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_line_eq:  0.0017008781433105469\n",
      "get_line_eq:  0.001651763916015625\n",
      "get_line_eq:  0.0017211437225341797\n",
      "get_line_eq:  0.001832723617553711\n",
      "get_line_eq:  0.0019562244415283203\n",
      "get_line_eq:  0.001867532730102539\n",
      "get_line_eq:  0.0017011165618896484\n",
      "get_line_eq:  0.001739501953125\n",
      "get_line_eq:  0.0017247200012207031\n",
      "get_line_eq:  0.001905679702758789\n",
      "get_line_eq:  0.001963376998901367\n",
      "get_line_eq:  0.0018987655639648438\n",
      "get_line_eq:  0.0019154548645019531\n",
      "get_line_eq:  0.0024237632751464844\n",
      "get_line_eq:  0.0019218921661376953\n",
      "get_line_eq:  0.0019445419311523438\n",
      "get_line_eq:  0.001918792724609375\n",
      "get_line_eq:  0.0018992424011230469\n",
      "get_line_eq:  0.0019490718841552734\n",
      "get_line_eq:  0.001905202865600586\n",
      "get_line_eq:  0.0019097328186035156\n",
      "get_line_eq:  0.001965761184692383\n",
      "get_line_eq:  0.0019123554229736328\n",
      "get_line_eq:  0.001924276351928711\n",
      "get_line_eq:  0.0019519329071044922\n",
      "get_line_eq:  0.0019180774688720703\n",
      "get_line_eq:  0.0019409656524658203\n",
      "get_line_eq:  0.0019109249114990234\n",
      "get_line_eq:  0.0018849372863769531\n",
      "get_line_eq:  0.001958131790161133\n",
      "get_line_eq:  0.0018985271453857422\n",
      "get_line_eq:  0.0019099712371826172\n",
      "get_line_eq:  0.0019583702087402344\n",
      "get_line_eq:  0.0019097328186035156\n",
      "get_line_eq:  0.001909017562866211\n",
      "get_line_eq:  0.001970529556274414\n",
      "get_line_eq:  0.0019104480743408203\n",
      "get_line_eq:  0.001959562301635742\n",
      "get_line_eq:  0.001894235610961914\n",
      "get_line_eq:  0.0018963813781738281\n",
      "get_line_eq:  0.0019502639770507812\n",
      "get_line_eq:  0.001894235610961914\n",
      "get_line_eq:  0.0018880367279052734\n",
      "get_line_eq:  0.0019757747650146484\n",
      "get_line_eq:  0.0019087791442871094\n",
      "get_line_eq:  0.0019016265869140625\n",
      "get_line_eq:  0.0023937225341796875\n",
      "get_line_eq:  0.0019292831420898438\n",
      "get_line_eq:  0.001993417739868164\n",
      "get_line_eq:  0.0016171932220458984\n",
      "get_line_eq:  0.0018973350524902344\n",
      "get_line_eq:  0.0017933845520019531\n",
      "get_line_eq:  0.001806020736694336\n",
      "get_line_eq:  0.0018405914306640625\n",
      "get_line_eq:  0.0017642974853515625\n",
      "get_line_eq:  0.0018188953399658203\n",
      "get_line_eq:  0.0017595291137695312\n",
      "get_line_eq:  0.0017499923706054688\n",
      "get_line_eq:  0.0018072128295898438\n",
      "get_line_eq:  0.0017588138580322266\n",
      "get_line_eq:  0.0019731521606445312\n",
      "get_line_eq:  0.0025539398193359375\n",
      "get_line_eq:  0.0020494461059570312\n",
      "get_line_eq:  0.0019290447235107422\n",
      "get_line_eq:  0.0020372867584228516\n",
      "get_line_eq:  0.0020492076873779297\n",
      "get_line_eq:  0.002076387405395508\n",
      "get_line_eq:  0.002029895782470703\n",
      "get_line_eq:  0.002004384994506836\n",
      "get_line_eq:  0.002096891403198242\n",
      "get_line_eq:  0.001963376998901367\n",
      "get_line_eq:  0.001949310302734375\n",
      "get_line_eq:  0.001966238021850586\n",
      "get_line_eq:  0.0019233226776123047\n",
      "get_line_eq:  0.0019142627716064453\n",
      "get_line_eq:  0.0019664764404296875\n",
      "get_line_eq:  0.001913309097290039\n",
      "get_line_eq:  0.001970529556274414\n",
      "get_line_eq:  0.0019004344940185547\n",
      "get_line_eq:  0.0018892288208007812\n",
      "get_line_eq:  0.0020287036895751953\n",
      "get_line_eq:  0.0018970966339111328\n",
      "get_line_eq:  0.0019135475158691406\n",
      "get_line_eq:  0.0019724369049072266\n",
      "get_line_eq:  0.0019178390502929688\n",
      "get_line_eq:  0.0019083023071289062\n",
      "get_line_eq:  0.001966714859008789\n",
      "get_line_eq:  0.0019102096557617188\n",
      "get_line_eq:  0.001958608627319336\n",
      "get_line_eq:  0.0018846988677978516\n",
      "get_line_eq:  0.0018956661224365234\n",
      "get_line_eq:  0.0019638538360595703\n",
      "get_line_eq:  0.0019028186798095703\n",
      "get_line_eq:  0.0018887519836425781\n",
      "get_line_eq:  0.002395153045654297\n",
      "get_line_eq:  0.0019390583038330078\n",
      "get_line_eq:  0.0019114017486572266\n",
      "get_line_eq:  0.0019745826721191406\n",
      "get_line_eq:  0.001689910888671875\n",
      "get_line_eq:  0.0017008781433105469\n",
      "get_line_eq:  0.0017771720886230469\n",
      "get_line_eq:  0.001695394515991211\n",
      "get_line_eq:  0.0017573833465576172\n",
      "get_line_eq:  0.0018970966339111328\n",
      "get_line_eq:  0.00165557861328125\n",
      "get_line_eq:  0.002089262008666992\n",
      "get_line_eq:  0.001699209213256836\n",
      "get_line_eq:  0.0021140575408935547\n",
      "get_line_eq:  0.0020279884338378906\n",
      "get_line_eq:  0.002001523971557617\n",
      "get_line_eq:  0.0020551681518554688\n",
      "get_line_eq:  0.001997709274291992\n",
      "get_line_eq:  0.0019881725311279297\n",
      "get_line_eq:  0.0020301342010498047\n",
      "get_line_eq:  0.001987934112548828\n",
      "get_line_eq:  0.001967191696166992\n",
      "get_line_eq:  0.002068042755126953\n",
      "get_line_eq:  0.0019614696502685547\n",
      "get_line_eq:  0.0018427371978759766\n",
      "get_line_eq:  0.0017271041870117188\n",
      "get_line_eq:  0.0017197132110595703\n",
      "get_line_eq:  0.0017914772033691406\n",
      "get_line_eq:  0.0017886161804199219\n",
      "get_line_eq:  0.0017809867858886719\n",
      "get_line_eq:  0.001829385757446289\n",
      "get_line_eq:  0.0017733573913574219\n",
      "get_line_eq:  0.0017518997192382812\n",
      "get_line_eq:  0.0018110275268554688\n",
      "get_line_eq:  0.001772165298461914\n",
      "get_line_eq:  0.00180816650390625\n",
      "get_line_eq:  0.0017681121826171875\n",
      "get_line_eq:  0.0019478797912597656\n",
      "get_line_eq:  0.0021088123321533203\n",
      "get_line_eq:  0.002046346664428711\n",
      "get_line_eq:  0.0020384788513183594\n",
      "get_line_eq:  0.0021016597747802734\n",
      "get_line_eq:  0.002010345458984375\n",
      "get_line_eq:  0.0019693374633789062\n",
      "get_line_eq:  0.002476215362548828\n",
      "get_line_eq:  0.0020415782928466797\n",
      "get_line_eq:  0.002097606658935547\n",
      "get_line_eq:  0.002040863037109375\n",
      "get_line_eq:  0.0020580291748046875\n",
      "get_line_eq:  0.002089977264404297\n",
      "get_line_eq:  0.002036571502685547\n",
      "get_line_eq:  0.0020284652709960938\n",
      "get_line_eq:  0.002088785171508789\n",
      "get_line_eq:  0.0016512870788574219\n",
      "get_line_eq:  0.0018243789672851562\n",
      "get_line_eq:  0.0018112659454345703\n",
      "get_line_eq:  0.0018033981323242188\n",
      "get_line_eq:  0.00225830078125\n",
      "get_line_eq:  0.0016777515411376953\n",
      "get_line_eq:  0.0018126964569091797\n",
      "get_line_eq:  0.0020089149475097656\n",
      "get_line_eq:  0.0020241737365722656\n",
      "get_line_eq:  0.002099275588989258\n",
      "get_line_eq:  0.0020279884338378906\n",
      "get_line_eq:  0.0020058155059814453\n",
      "get_line_eq:  0.002102375030517578\n",
      "get_line_eq:  0.0020072460174560547\n",
      "get_line_eq:  0.002006053924560547\n",
      "get_line_eq:  0.0020639896392822266\n",
      "get_line_eq:  0.002020597457885742\n",
      "get_line_eq:  0.0020580291748046875\n",
      "get_line_eq:  0.002026796340942383\n",
      "get_line_eq:  0.001967906951904297\n",
      "get_line_eq:  0.002078533172607422\n",
      "get_line_eq:  0.0020165443420410156\n",
      "get_line_eq:  0.0020079612731933594\n",
      "get_line_eq:  0.0020751953125\n",
      "get_line_eq:  0.0020265579223632812\n",
      "get_line_eq:  0.002000093460083008\n",
      "get_line_eq:  0.0020999908447265625\n",
      "get_line_eq:  0.0020837783813476562\n",
      "get_line_eq:  0.0020635128021240234\n",
      "get_line_eq:  0.0020170211791992188\n",
      "get_line_eq:  0.0020432472229003906\n",
      "get_line_eq:  0.0020766258239746094\n",
      "get_line_eq:  0.001997232437133789\n",
      "get_line_eq:  0.0020041465759277344\n",
      "get_line_eq:  0.0020606517791748047\n",
      "get_line_eq:  0.0020041465759277344\n",
      "get_line_eq:  0.002009868621826172\n",
      "get_line_eq:  0.002569437026977539\n",
      "get_line_eq:  0.0019011497497558594\n",
      "get_line_eq:  0.001953601837158203\n",
      "get_line_eq:  0.0018951892852783203\n",
      "get_line_eq:  0.0019114017486572266\n",
      "get_line_eq:  0.0019440650939941406\n",
      "get_line_eq:  0.0018928050994873047\n",
      "get_line_eq:  0.0018734931945800781\n",
      "get_line_eq:  0.001953125\n",
      "get_line_eq:  0.0018804073333740234\n",
      "get_line_eq:  0.001889944076538086\n",
      "get_line_eq:  0.002020597457885742\n",
      "total_time:  10.275548458099365\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "#shitty hard coding\n",
    "params[\"n_mem\"] = 32768  #32768 #49152 for color, 32768 for grayscale\n",
    "\n",
    "#general params\n",
    "params[\"run_name\"] = \"7680_med_compress_pcm\"\n",
    "params[\"file_location\"] = \"/media/tbell/datasets/natural_images.txt\"\n",
    "params[\"gpu_ids\"] = [\"0\"]\n",
    "params[\"output_location\"] = os.path.expanduser(\"~\")+\"/CAE_Project/CAEs/model_outputs/\"+params[\"run_name\"]\n",
    "params[\"num_threads\"] = 6\n",
    "params[\"num_epochs\"] = 40\n",
    "params[\"epoch_size\"] = 112682\n",
    "params[\"eval_interval\"] = 100\n",
    "params[\"seed\"] = 1234567890\n",
    "\n",
    "#checkpoint params\n",
    "params[\"run_from_check\"] = False\n",
    "params[\"check_load_run_name\"] = \"train\"\n",
    "params[\"check_load_path\"] = \"/home/dpaiton/CAE_Project/CAEs/model_outputs/\"+params[\"check_load_run_name\"]+\"/checkpoints/chkpt_-22800\"\n",
    "\n",
    "#image params\n",
    "params[\"shuffle_inputs\"] = True\n",
    "params[\"batch_size\"] = 100\n",
    "params[\"img_shape_y\"] = 256\n",
    "params[\"num_colors\"] = 1\n",
    "params[\"downsample_images\"] = True\n",
    "params[\"downsample_method\"] = \"resize\" # can be \"crop\" or \"resize\"\n",
    "\n",
    "#learning rates\n",
    "params[\"init_learning_rate\"] = 5.0e-4\n",
    "params[\"decay_steps\"] = 10000#epoch_size*0.5*num_epochs #0.5*epoch_size\n",
    "params[\"staircase\"] = True\n",
    "params[\"decay_rate\"] = 0.9\n",
    "\n",
    "#layer params\n",
    "params[\"memristorify\"] = False\n",
    "params[\"god_damn_network\"] = True\n",
    "params[\"relu\"] = False\n",
    "\n",
    "#layer dimensions\n",
    "params[\"input_channels\"] = [params[\"num_colors\"], 128, 128]\n",
    "params[\"output_channels\"] = [128, 128, 128]\n",
    "params[\"patch_size_y\"] = [9, 5, 5]\n",
    "params[\"strides\"] = [4, 2, 2]\n",
    "\n",
    "#memristor params\n",
    "params[\"GAMMA\"] = 1.0  # slope of the out of bounds cost\n",
    "params[\"mem_v_min\"] = -1.0\n",
    "params[\"mem_v_max\"] = 1.0\n",
    "params[\"gauss_chan\"] = False\n",
    "\n",
    "cae_model = cae(params)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = False\n",
    "config.log_device_placement = False # for debugging - log devices used by each variable\n",
    "\n",
    "with tf.Session(config=config, graph=cae_model.graph) as sess:\n",
    "  sess.run(cae_model.init_op)\n",
    "  if cae_model.params[\"run_from_check\"] == True:\n",
    "    cae_model.full_saver.restore(sess, cae_model.params[\"check_load_path\"])\n",
    "  # Coordinator manages threads, checks for stopping requests\n",
    "  coord = tf.train.Coordinator()\n",
    "  # queue_runners are created by helper functions tf.train.string_input_producer() and tf.train.batch_join()\n",
    "  enqueue_threads = tf.train.start_queue_runners(sess, coord=coord, start=True)\n",
    "\n",
    "  #_, step, u_list = sess.run([cae_model.train_op, cae_model.global_step, cae_model.u_list])\n",
    "  #u_vals = u_list[int(params[\"num_layers\"]/2)]\n",
    "  t0 = time.time()\n",
    "  latent_ent_list, u_list = sess.run([cae_model.latent_entropies, cae_model.u_list])\n",
    "  t1 = time.time()\n",
    "  t_tot = t1-t0\n",
    "  print(\"total_time: \",t_tot)\n",
    "  \n",
    "  coord.request_stop()\n",
    "  coord.join(enqueue_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_hists(latent_vals, u_vals, num_plots):\n",
    "    fig, ax = plt.subplots(num_plots, figsize=(20, 5*num_plots))\n",
    "    if num_plots == 1:\n",
    "        ax = [ax]\n",
    "    for plot in range(num_plots):\n",
    "        entropy, hist, bin_edges = latent_vals[plot]\n",
    "        ax[plot].scatter(bin_edges, hist)\n",
    "        for index in np.arange(len(hist[:-1])):\n",
    "          x_points = [bin_edges[index], bin_edges[index+1]]\n",
    "          y_points = [hist[index], hist[index+1]]\n",
    "          ax[plot].plot(x_points, y_points, linewidth=2, color=\"k\")\n",
    "        ax[plot].set_title(\"Entropy=\"+str(round(entropy,2)), fontsize=18)\n",
    "        ylim = ax[plot].get_ylim()\n",
    "        ax[plot].set_ylim((0, ylim[1]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_plots = 2\n",
    "rand_val_index = np.random.choice(len(latent_ent_list), num_plots)\n",
    "latent_vals = [latent_ent_list[idx] for idx in rand_val_index]\n",
    "u_vals = tf.reshape(u_list[int(params[\"num_layers\"]/2)], shape=(params[\"batch_size\"], params[\"n_mem\"]), name=\"u_vals\")\n",
    "plot_hists(latent_vals, u_vals=u_vals, num_plots=num_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_vals = tf.reshape(u_list[int(params[\"num_layers\"]/2)],\n",
    "                    shape=(params[\"batch_size\"], \n",
    "                    params[\"n_mem\"]), \n",
    "                    name=\"u_vals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_line_eq(x_points, y_points):\n",
    "    m = tf.divide(tf.subtract(y_points[1],y_points[0]),tf.subtract(x_points[1],x_points[0]))\n",
    "    b = tf.subtract(y_points[1],tf.multiply(m,x_points[1]))\n",
    "    return (m,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ms_and_bs(data):\n",
    "    ms = []\n",
    "    bs = []\n",
    "    x0s = []\n",
    "    x1s = []\n",
    "    for xy_points in data:\n",
    "        m,b = get_line_eq(xy_points[0], xy_points[1])\n",
    "        ms.append(m)\n",
    "        bs.append(b)\n",
    "        x0s.append(xy_points[0][0])\n",
    "        x1s.append(xy_points[0][1])\n",
    "    return (ms, bs, x0s, x1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def integral_end_point(x,m,b):\n",
    "    m_x = tf.multiply(m,x)\n",
    "    line = tf.add(m_x,b)\n",
    "    two_line_sq = tf.multiply(tf.constant(2.0),tf.square(line))\n",
    "    left_side = tf.multiply(two_line_sq,tf.log(line))\n",
    "    \n",
    "    two_b = tf.multiply(tf.constant(2.0),b)\n",
    "    right_side = tf.multiply(m_x,tf.add(m_x,two_b))\n",
    "    \n",
    "    numerator = tf.multiply(tf.constant(-1.0),tf.subtract(left_side,right_side))\n",
    "    denom = tf.multiply(tf.constant(4.0),m)\n",
    "    \n",
    "    return tf.divide(numerator,denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_differential_entropy(x_points, y_points, m, b):\n",
    "    def m_equal_0():\n",
    "        def b_equal_0():\n",
    "            return tf.constant(0.0)\n",
    "        def b_nequal_0():\n",
    "            x_1_end = tf.multiply(tf.multiply(x_points[1],tf.log(b)),tf.multiply(tf.constant(-1.0),b))\n",
    "            x_0_end = tf.multiply(tf.multiply(x_points[0],tf.log(b)),tf.multiply(tf.constant(-1.0),b))\n",
    "            return  tf.subtract(x_1_end,x_0_end)\n",
    "        return tf.cond(tf.equal(b,tf.constant(0.0)), b_equal_0, b_nequal_0)\n",
    "    def m_nequal_0():\n",
    "        def y_neg():\n",
    "            return tf.constant(0.0)\n",
    "        def y_pos():\n",
    "            return tf.subtract(integral_end_point(x_points[1],m,b),integral_end_point(x_points[0],m,b))\n",
    "        return tf.cond(tf.logical_or(tf.less_equal(tf.add(tf.multiply(m,x_points[1]),b),tf.constant(0.0)),\n",
    "                                     tf.less_equal(tf.add(tf.multiply(m,x_points[0]),b),tf.constant(0.0))),\n",
    "                                     y_neg,y_pos)\n",
    "    return tf.cond(tf.equal(m,tf.constant(0.0)), m_equal_0, m_nequal_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_points = [tf.constant(10.0),tf.constant(1.0)]\n",
    "y_points = [tf.constant(1.0),tf.constant(1.0)]\n",
    "m = tf.constant(2.0)\n",
    "b = tf.constant(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as dat_shit:\n",
    "    print (dat_shit.run(get_differential_entropy(x_points,y_points,m,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_area(ms, bs, x0s, x1s):\n",
    "    total_area=tf.constant(0.0)\n",
    "    for m,b,x0,x1 in zip(ms,bs,x0s,x1s):\n",
    "        left_side = tf.multiply(tf.constant(0.5),tf.multiply(m,tf.subtract(tf.square(x1),tf.square(x0))))\n",
    "        rigt_side = tf.multiply(b,tf.subtract(x1,x0))        \n",
    "        unit_area = tf.add(left_side,rigt_side)\n",
    "        total_area = tf.add(total_area,unit_area)\n",
    "    return total_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_normalized_points(xy_points, area, m0, b0):\n",
    "    x0 = xy_points[0][0]  \n",
    "    x1 = xy_points[0][1]\n",
    "    x_diff = tf.subtract(x1,x0)\n",
    "    x_diff_sq = tf.subtract(tf.square(x1),tf.square(x0))\n",
    "    left_num = tf.add(tf.multiply(x_diff_sq,tf.multiply(tf.constant(0.5),m0)),tf.multiply(b0,x_diff))\n",
    "    left_denom = tf.multiply(area,x_diff)\n",
    "    left_side = tf.divide(left_num,left_denom)\n",
    "    right_side = tf.divide(tf.multiply(tf.multiply(tf.constant(0.5),m0),x_diff_sq),x_diff)\n",
    "    new_b = tf.subtract(left_side,right_side)\n",
    "    new_y0 = tf.add(tf.multiply(m0,xy_points[0][0]),new_b)\n",
    "    new_y1 = tf.add(tf.multiply(m0,xy_points[0][1]),new_b)\n",
    "    new_points = [[xy_points[0][0], xy_points[0][1]], [new_y0,new_y1]]\n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bool_test(test_a,test_b):\n",
    "    def true_case():\n",
    "        return tf.constant(\"shit's true!\")\n",
    "    def false_case():\n",
    "        return tf.constant(\"shit's false!\")\n",
    "    #num_matching = tf.reduce_sum(tf.where(tf.equal(test_a, test_b), tf.ones_like(test_a), tf.zeros_like(test_a)))\n",
    "    #num_matching = tf.reduce_sum(tf.to_int32(tf.equal(test_a, test_b)))\n",
    "    #return tf.cond(tf.equal(tf.constant(0),tf.shape(tf.where(tf.equal(test_a,test_b)))[0]),true_case,false_case)\n",
    "    return tf.cond(tf.equal(tf.constant(0), tf.reduce_sum(tf.to_int32(tf.equal(test_a, test_b)))), true_case, false_case)\n",
    "\n",
    "with tf.Session() as dat_shit_4:\n",
    "    print(dat_shit_4.run(bool_test(tf.constant([1.0,0.0]),tf.constant([0.0,0.0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unit_entropy(data, eps=None):\n",
    "    ms, bs, x0s, x1s = get_ms_and_bs(data)\n",
    "    area = compute_area(ms, bs, x0s, x1s)\n",
    "    new_data = []\n",
    "    for idx, xy_points in enumerate(data):\n",
    "        m0 = ms[idx]\n",
    "        b0 = bs[idx]\n",
    "        xy_points = get_normalized_points(xy_points, area, m0, b0)\n",
    "        new_data.append(xy_points)\n",
    "    ms, bs, x0s, x1s = get_ms_and_bs(new_data)\n",
    "    \n",
    "    zeros_tensor = tf.constant([0.0,0.0])\n",
    "    entropy = tf.constant(0.0)\n",
    "    for idx, xy_points in enumerate(new_data):\n",
    "        m = ms[idx]\n",
    "        b = bs[idx]\n",
    "    \n",
    "        xy_points_tensor = xy_points[1]\n",
    "    \n",
    "        def points_zero_check(xy_points_tensor,zeros_tensor):\n",
    "            def points_zero():\n",
    "                return tf.add(entropy,tf.constant(0.0))\n",
    "            def points_nzero():    \n",
    "                def eps_not_None():\n",
    "                    def xy_points_both_nzero():\n",
    "                        return tf.add(entropy,get_differential_entropy(xy_points[0], xy_points[1], m, b))\n",
    "                    def one_xy_points_nzero():\n",
    "                        def xy_points_0_zero():\n",
    "                            xy_points[1][0] = tf.add(xy_points[1][0],eps)\n",
    "                            return tf.add(entropy,get_differential_entropy(xy_points[0], xy_points[1], m, b))\n",
    "                        def xy_points_1_zero():\n",
    "                            xy_points[1][1] = tf.add(xy_points[1][1],eps)\n",
    "                            return tf.add(entropy,get_differential_entropy(xy_points[0], xy_points[1], m, b))\n",
    "                        return tf.cond(tf.equal(xy_points[1][0],tf.constant(0.0)),\n",
    "                                       xy_points_0_zero,\n",
    "                                       xy_points_1_zero)   \n",
    "                    return tf.cond(tf.equal(tf.constant(0),tf.shape(tf.where(tf.equal(xy_points_tensor,zeros_tensor)))[0]),\n",
    "                                   xy_points_both_nzero,\n",
    "                                   one_xy_points_nzero)   \n",
    "                def eps_None():\n",
    "                    return tf.add(entropy,get_differential_entropy(xy_points[0], xy_points[1], m, b))\n",
    "                return tf.cond(tf.not_equal(eps, None), eps_not_None, eps_None)\n",
    "            return tf.cond(tf.equal(tf.size(xy_points_tensor),tf.shape(tf.where(tf.equal(xy_points_tensor,zeros_tensor)))[0]),\n",
    "                           points_zero,\n",
    "                           points_nzero)\n",
    "        entropy = tf.add(entropy, points_zero_check(xy_points_tensor,zeros_tensor))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def var(xs,ys):\n",
    "    mean_xs = tf.divide(tf.matmul(xs,tf.transpose(ys)),tf.size(xs))\n",
    "    norm_mean = tf.square(tf.subtract(xs,mean_xs))\n",
    "    var_xs = tf.matmul(norm_mean,tf.transpose(ys))\n",
    "    return var_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_entropy(u_val, num_bins):\n",
    "    value_range = [tf.reduce_min(u_val), tf.reduce_max(u_val)]\n",
    "    hist = tf.histogram_fixed_width(u_val, value_range=value_range, bins=num_bins)\n",
    "    bin_edges = tf.linspace(start=value_range[0], stop=value_range[1], num=num_bins)\n",
    "    hist = tf.divide(hist,tf.reduce_sum(hist))\n",
    "    \n",
    "    for index in np.arange(len(hist[:-1])):\n",
    "        x_points = [bin_edges[index], bin_edges[index+1]]\n",
    "        y_points = [hist[index], hist[index+1]]\n",
    "        hist_data.append((x_points, y_points))\n",
    "    entropy = unit_entropy(hist_data, eps=1e-12)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
